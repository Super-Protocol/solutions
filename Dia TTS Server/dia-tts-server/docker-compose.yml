version: '3.8'

services:
  dia-tts-server:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "${PORT:-8003}:${PORT:-8003}"
    volumes:
      # Mount local directories into the container for persistent data
      - ./model_cache:/app/model_cache
      - ./reference_audio:/app/reference_audio
      - ./outputs:/app/outputs
      - ./voices:/app/voices
      # DO NOT mount config.yaml - let the app create it inside

    # --- GPU Access ---
    # Modern method (Recommended for newer Docker/NVIDIA setups)
    devices:
      - nvidia.com/gpu=all
    device_cgroup_rules:
      - "c 195:* rmw" # Needed for some NVIDIA container toolkit versions
      - "c 236:* rmw" # Needed for some NVIDIA container toolkit versions

    # Legacy method (Alternative for older Docker/NVIDIA setups)
    # If the 'devices' block above doesn't work, comment it out and uncomment
    # the 'deploy' block below. Do not use both simultaneously.
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1 # Or specify specific GPUs e.g., "device=0,1"
    #           capabilities: [gpu]
    # --- End GPU Access ---

    restart: unless-stopped
    env_file:
      # Load environment variables from .env file for initial config seeding
      - .env
    environment:
      # Enable faster Hugging Face downloads inside the container
      - HF_HUB_ENABLE_HF_TRANSFER=1
      # Pass GPU capabilities (may be needed for legacy method if uncommented)
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
